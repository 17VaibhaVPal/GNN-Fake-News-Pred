{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13984787,"sourceType":"datasetVersion","datasetId":8914055}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 1\nimport os, numpy as np, pandas as pd\n\nDATA_DIR = \"/kaggle/input/gnn-fakenews-graph-data\"\nprint(\"DATA_DIR:\", DATA_DIR)\nprint(\"Files:\", sorted(os.listdir(DATA_DIR)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:38:17.706937Z","iopub.execute_input":"2025-12-04T06:38:17.707500Z","iopub.status.idle":"2025-12-04T06:38:17.718319Z","shell.execute_reply.started":"2025-12-04T06:38:17.707472Z","shell.execute_reply":"2025-12-04T06:38:17.717756Z"}},"outputs":[{"name":"stdout","text":"DATA_DIR: /kaggle/input/gnn-fakenews-graph-data\nFiles: ['A.txt', 'graph_labels.npy', 'new_bert_feature.npz', 'new_content_feature.npz', 'new_profile_feature.npz', 'node_graph_id.npy']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 2 — Load arrays & inspect shapes\n\nimport numpy as np\nimport os\n\nA_path = os.path.join(DATA_DIR, \"A.txt\")\nnode_graph_id = np.load(os.path.join(DATA_DIR, \"node_graph_id.npy\"))\ngraph_labels = np.load(os.path.join(DATA_DIR, \"graph_labels.npy\"))\nbert = np.load(os.path.join(DATA_DIR, \"new_bert_feature.npz\"))[\"data\"]\nprofile = np.load(os.path.join(DATA_DIR, \"new_profile_feature.npz\"))[\"data\"]\ncontent = np.load(os.path.join(DATA_DIR, \"new_content_feature.npz\"))[\"data\"]\n\nprint(\"node_graph_id shape:\", node_graph_id.shape)\nprint(\"graph_labels shape:\", graph_labels.shape)\nprint(\"bert shape:\", bert.shape)\nprint(\"profile shape:\", profile.shape)\nprint(\"content shape:\", content.shape)\n\n# show first 5 edges only\nprint(\"\\nSample edges from A.txt:\")\nwith open(A_path) as f:\n    for _ in range(5):\n        print(f.readline().strip())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:44:28.372056Z","iopub.execute_input":"2025-12-04T06:44:28.372896Z","iopub.status.idle":"2025-12-04T06:44:28.998975Z","shell.execute_reply.started":"2025-12-04T06:44:28.372868Z","shell.execute_reply":"2025-12-04T06:44:28.998141Z"}},"outputs":[{"name":"stdout","text":"node_graph_id shape: (5425,)\ngraph_labels shape: (500,)\nbert shape: (5425, 768)\nprofile shape: (5425, 10)\ncontent shape: (5425, 310)\n\nSample edges from A.txt:\n0 1\n0 2\n0 3\n0 4\n0 5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Install PyTorch Geometric on Kaggle\n# This installs the correct wheels that match the PyTorch version on Kaggle\n\n!pip install -q torch_geometric\n!pip install -q torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:46:38.317387Z","iopub.execute_input":"2025-12-04T06:46:38.317724Z","iopub.status.idle":"2025-12-04T06:46:50.402544Z","shell.execute_reply.started":"2025-12-04T06:46:38.317690Z","shell.execute_reply":"2025-12-04T06:46:50.401842Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.0/494.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.9/750.9 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch_geometric\nimport torch\nfrom torch_geometric.data import Data\n\nprint(\"PyG version:\", torch_geometric.__version__)\nprint(\"Torch version:\", torch.__version__)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install PyTorch Geometric (PyG) for PyTorch 2.6.0 CPU build\n!pip install -q torch_geometric\n\n# Install CPU wheels compatible with PyTorch 2.6.0\n!pip install -q \\\n    torch_scatter \\\n    torch_sparse \\\n    torch_cluster \\\n    torch_spline_conv \\\n    -f https://data.pyg.org/whl/torch-2.6.0+cpu.html\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:29:36.597838Z","iopub.execute_input":"2025-12-05T18:29:36.598712Z","iopub.status.idle":"2025-12-05T18:29:48.222278Z","shell.execute_reply.started":"2025-12-05T18:29:36.598684Z","shell.execute_reply":"2025-12-05T18:29:48.221454Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.2/545.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.1/781.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch_geometric\nfrom torch_geometric.data import Data, Dataset\nimport torch\n\nprint(\"PyG version:\", torch_geometric.__version__)\nprint(\"Torch version:\", torch.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:29:49.372791Z","iopub.execute_input":"2025-12-05T18:29:49.373589Z","iopub.status.idle":"2025-12-05T18:29:57.434045Z","shell.execute_reply.started":"2025-12-05T18:29:49.373555Z","shell.execute_reply":"2025-12-05T18:29:57.433159Z"}},"outputs":[{"name":"stdout","text":"PyG version: 2.7.0\nTorch version: 2.6.0+cu124\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# CELL 4.1 — define GAT and GraphSAGE and model factory\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GATConv, SAGEConv, global_mean_pool, GCNConv\n\nclass GCNGraphClassifier(nn.Module):\n    def __init__(self, in_channels, hidden=128, num_classes=2):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, hidden)\n        self.conv2 = GCNConv(hidden, hidden)\n        self.lin = nn.Linear(hidden, num_classes)\n    def forward(self, x, edge_index, batch):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\nclass GATGraphClassifier(nn.Module):\n    def __init__(self, in_channels, hidden=128, num_classes=2, heads=4):\n        super().__init__()\n        # produce hidden total = hidden\n        self.gat1 = GATConv(in_channels, hidden // heads, heads=heads)\n        self.gat2 = GATConv(hidden, hidden // heads, heads=heads)\n        self.lin = nn.Linear(hidden, num_classes)\n    def forward(self, x, edge_index, batch):\n        x = F.elu(self.gat1(x, edge_index))\n        x = F.elu(self.gat2(x, edge_index))\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\nclass SAGEGraphClassifier(nn.Module):\n    def __init__(self, in_channels, hidden=128, num_classes=2):\n        super().__init__()\n        self.sage1 = SAGEConv(in_channels, hidden)\n        self.sage2 = SAGEConv(hidden, hidden)\n        self.lin = nn.Linear(hidden, num_classes)\n    def forward(self, x, edge_index, batch):\n        x = F.relu(self.sage1(x, edge_index))\n        x = F.relu(self.sage2(x, edge_index))\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\ndef get_model(name, in_channels, hidden=128):\n    name = name.lower()\n    if name == \"gcn\":\n        return GCNGraphClassifier(in_channels, hidden)\n    if name == \"gat\":\n        return GATGraphClassifier(in_channels, hidden)\n    if name == \"sage\":\n        return SAGEGraphClassifier(in_channels, hidden)\n    raise ValueError(\"Unknown model: \"+name)\n\nprint(\"Defined GCN, GAT, GraphSAGE and get_model() factory.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:31:37.180458Z","iopub.execute_input":"2025-12-05T18:31:37.181045Z","iopub.status.idle":"2025-12-05T18:31:37.192135Z","shell.execute_reply.started":"2025-12-05T18:31:37.181017Z","shell.execute_reply":"2025-12-05T18:31:37.191237Z"}},"outputs":[{"name":"stdout","text":"Defined GCN, GAT, GraphSAGE and get_model() factory.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# CELL 4.2 — training utilities + checkpointing\nimport torch\nfrom sklearn.metrics import accuracy_score, f1_score\nimport os\n\ndef train_one_epoch(model, loader, optimizer, loss_fn, device):\n    model.train()\n    total_loss = 0.0\n    total = 0\n    correct = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index, batch.batch)\n        loss = loss_fn(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=1)\n        correct += (preds == batch.y).sum().item()\n        total += batch.num_graphs\n    return total_loss / total, correct / total\n\ndef evaluate_model(model, loader, device):\n    model.eval()\n    ys, preds = [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            p = out.argmax(dim=1).cpu().numpy()\n            preds.extend(p.tolist())\n            ys.extend(batch.y.cpu().numpy().tolist())\n    return {\n        \"accuracy\": accuracy_score(ys, preds),\n        \"f1_macro\": f1_score(ys, preds, average='macro')\n    }\n\ndef run_training(model_name, train_loader, val_loader, in_channels, device,\n                 epochs=2, lr=1e-3, hidden=128, checkpoint_dir=\"/kaggle/working/checkpoints\"):\n    model = get_model(model_name, in_channels, hidden).to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=lr)\n    loss_fn = torch.nn.CrossEntropyLoss()\n    os.makedirs(checkpoint_dir, exist_ok=True)\n\n    best_val_f1 = -1.0\n    best_path = None\n    history = {\"epoch\":[], \"train_loss\":[], \"train_acc\":[], \"val_acc\":[], \"val_f1\":[]}\n\n    for epoch in range(1, epochs+1):\n        train_loss, train_acc = train_one_epoch(model, train_loader, opt, loss_fn, device)\n        val = evaluate_model(model, val_loader, device)\n        val_acc, val_f1 = val[\"accuracy\"], val[\"f1_macro\"]\n        print(f\"[{model_name}] Epoch {epoch}: train_loss={train_loss:.4f} train_acc={train_acc:.4f} val_acc={val_acc:.4f} val_f1={val_f1:.4f}\")\n\n        history[\"epoch\"].append(epoch)\n        history[\"train_loss\"].append(train_loss)\n        history[\"train_acc\"].append(train_acc)\n        history[\"val_acc\"].append(val_acc)\n        history[\"val_f1\"].append(val_f1)\n\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            best_path = os.path.join(checkpoint_dir, f\"best_{model_name}.pt\")\n            torch.save(model.state_dict(), best_path)\n            print(f\"Saved best model to {best_path}\")\n\n    return history, best_path\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:31:31.477770Z","iopub.execute_input":"2025-12-05T18:31:31.478636Z","iopub.status.idle":"2025-12-05T18:31:31.489947Z","shell.execute_reply.started":"2025-12-05T18:31:31.478609Z","shell.execute_reply":"2025-12-05T18:31:31.489172Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# CELL 4.3 — run short experiments (2 epochs) for GCN, GAT, GraphSAGE\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nin_channels = graph_list[0].num_node_features\nmodels_to_test = [\"gcn\", \"gat\", \"sage\"]\nresults = {}\n\nfor mname in models_to_test:\n    print(\"\\n=== Running model:\", mname, \"===\")\n    hist, best_path = run_training(mname, train_loader, val_loader, in_channels, device,\n                                  epochs=2, lr=1e-3, hidden=128,\n                                  checkpoint_dir=\"/kaggle/working/checkpoints\")\n    results[mname] = {\"history\": hist, \"best_path\": best_path}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T18:32:04.689474Z","iopub.execute_input":"2025-12-05T18:32:04.690303Z","iopub.status.idle":"2025-12-05T18:32:04.828278Z","shell.execute_reply.started":"2025-12-05T18:32:04.690276Z","shell.execute_reply":"2025-12-05T18:32:04.827226Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3907274765.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# CELL 4.3 — run short experiments (2 epochs) for GCN, GAT, GraphSAGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodels_to_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"gcn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'graph_list' is not defined"],"ename":"NameError","evalue":"name 'graph_list' is not defined","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"pip install torch torchvision torchaudio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T05:20:16.035640Z","iopub.execute_input":"2025-12-06T05:20:16.035928Z","iopub.status.idle":"2025-12-06T05:21:31.155055Z","shell.execute_reply.started":"2025-12-06T05:20:16.035900Z","shell.execute_reply":"2025-12-06T05:21:31.154327Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Single recovery cell: install PyG if missing, reload arrays, load or rebuild graph_list, make loaders.\nimport os, sys, random, numpy as np, torch, pathlib\nfrom collections import defaultdict\n\n# ----- PARAMETERS -----\nDATA_DIR = \"/kaggle/input/gnn-fakenews-graph-data\"\nSAVED_LOCATIONS = [\n    \"/kaggle/working/graph_dataset/graph_list_500.pt\",\n    \"/kaggle/working/graph_list_500.pt\",\n    \"/kaggle/input/graph-list/graph_list_500.pt\",   # if you uploaded saved list as a dataset\n]\nMAX_GRAPHS = 500   # rebuild up to this many graphs if needed\nBATCH_SIZE = 32\nMIN_NODES_PER_GRAPH = 2\nSEED = 42\n\n# ----- 1) ensure PyG installed (safe to run even if already installed) -----\ntry:\n    import torch_geometric\nexcept Exception:\n    print(\"Installing PyG (this may take a moment)...\")\n    !pip install -q torch_geometric\n    !pip install -q torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cpu.html\n    import importlib\n    importlib.invalidate_caches()\n    print(\"Installed PyG; continuing.\")\n\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\n\n# ----- 2) load base arrays if not present -----\nneed_reload_arrays = False\nif 'node_graph_id' in globals() and 'bert' in globals() and 'profile' in globals() and 'graph_labels' in globals():\n    print(\"Found arrays in memory: node_graph_id, bert, profile, graph_labels.\")\nelse:\n    need_reload_arrays = True\n\nif need_reload_arrays:\n    print(\"Loading arrays from DATA_DIR:\", DATA_DIR)\n    try:\n        node_graph_id = np.load(os.path.join(DATA_DIR, \"node_graph_id.npy\"))\n        graph_labels = np.load(os.path.join(DATA_DIR, \"graph_labels.npy\"))\n        bert = np.load(os.path.join(DATA_DIR, \"new_bert_feature.npz\"))[\"data\"]\n        profile = np.load(os.path.join(DATA_DIR, \"new_profile_feature.npz\"))[\"data\"]\n        content = np.load(os.path.join(DATA_DIR, \"new_content_feature.npz\"))[\"data\"]\n        print(\"Loaded arrays shapes:\", node_graph_id.shape, graph_labels.shape, bert.shape, profile.shape, content.shape)\n    except Exception as e:\n        raise RuntimeError(\"Could not load dataset arrays from DATA_DIR. Check DATA_DIR and files. Error: \"+repr(e))\n\n# ----- 3) try to load saved graph_list from common locations -----\ngraph_list = None\nfor p in SAVED_LOCATIONS:\n    if os.path.exists(p):\n        try:\n            print(\"Found saved graph_list at:\", p, \" — loading...\")\n            graph_list = torch.load(p)\n            print(\"Loaded graph_list length:\", len(graph_list))\n            break\n        except Exception as e:\n            print(\"Found but failed to load\", p, \":\", e)\n\n# also check if user uploaded under /kaggle/input\n# search /kaggle/input for graph_list_*.pt\nif graph_list is None:\n    for root, dirs, files in os.walk(\"/kaggle/input\"):\n        for f in files:\n            if f.startswith(\"graph_list\") and f.endswith(\".pt\"):\n                p = os.path.join(root, f)\n                try:\n                    print(\"Found graph_list in /kaggle/input at\", p, \" — loading...\")\n                    graph_list = torch.load(p)\n                    print(\"Loaded graph_list length:\", len(graph_list))\n                    break\n                except Exception as e:\n                    print(\"Found but failed to load\", p, \":\", e)\n        if graph_list is not None:\n            break\n\n# ----- 4) if not found, rebuild graph_list (memory-aware) -----\nif graph_list is None:\n    print(\"No saved graph_list found — rebuilding up to MAX_GRAPHS =\", MAX_GRAPHS)\n    # load A.txt edges\n    A_path = os.path.join(DATA_DIR, \"A.txt\")\n    edges_full = []\n    with open(A_path) as f:\n        for line in f:\n            u,v = map(int, line.strip().split())\n            edges_full.append((u,v))\n    edges_full = np.array(edges_full, dtype=np.int64)\n    edges_list = [tuple(e) for e in edges_full.tolist()]\n\n    # map graph_id -> list of node ids\n    graph_to_nodes = defaultdict(list)\n    for nid, gid in enumerate(node_graph_id):\n        graph_to_nodes[int(gid)].append(nid)\n    print(\"Total available graphs:\", len(graph_to_nodes))\n\n    graph_list = []\n    built = 0\n    skipped = 0\n    for gid, nodes in list(graph_to_nodes.items()):\n        if built >= MAX_GRAPHS:\n            break\n        nodes_sorted = sorted(nodes)\n        if len(nodes_sorted) < MIN_NODES_PER_GRAPH:\n            skipped += 1\n            continue\n        node_set = set(nodes_sorted)\n        g2l = {g:i for i,g in enumerate(nodes_sorted)}\n        e_local = []\n        # iterate global edges and add those internal to this graph\n        for (u,v) in edges_list:\n            if u in node_set and v in node_set:\n                e_local.append([g2l[u], g2l[v]])\n        if len(e_local) == 0:\n            skipped += 1\n            continue\n        edge_index = torch.tensor(e_local, dtype=torch.long).t().contiguous()\n        x_sub = torch.from_numpy(np.hstack([bert[nodes_sorted], profile[nodes_sorted]])).float()\n        y = torch.tensor([int(graph_labels[gid])], dtype=torch.long)\n        data_obj = Data(x=x_sub, edge_index=edge_index, y=y)\n        graph_list.append(data_obj)\n        built += 1\n    print(\"Built graphs:\", built, \"Skipped:\", skipped)\n    # save for future runs (session working dir)\n    out_dir = \"/kaggle/working/graph_dataset\"\n    os.makedirs(out_dir, exist_ok=True)\n    torch.save(graph_list, os.path.join(out_dir, f\"graph_list_{built}.pt\"))\n    print(\"Saved built graph_list to\", os.path.join(out_dir, f\"graph_list_{built}.pt\"))\n\n# ----- 5) create train/val DataLoaders -----\nrandom.shuffle(graph_list)\nsplit = int(0.8 * len(graph_list))\ntrain_list = graph_list[:split]\nval_list = graph_list[split:]\ntrain_loader = DataLoader(train_list, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_list, batch_size=BATCH_SIZE)\nprint(\"Prepared DataLoaders -> train:\", len(train_list), \"val:\", len(val_list))\nprint(\"Example batch shapes (first batch):\")\nfor batch in train_loader:\n    print(\" batch.x.shape:\", batch.x.shape)\n    print(\" batch.edge_index.shape:\", batch.edge_index.shape)\n    print(\" batch.y.shape:\", batch.y.shape)\n    break\n\n# expose into globals for subsequent cells\nglobals().update({\n    \"graph_list\": graph_list,\n    \"train_list\": train_list,\n    \"val_list\": val_list,\n    \"train_loader\": train_loader,\n    \"val_loader\": val_loader\n})\nprint(\"Setup complete. Ready to run experiments (CELL 4.3).\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T05:21:39.342983Z","iopub.execute_input":"2025-12-06T05:21:39.343463Z","iopub.status.idle":"2025-12-06T05:21:57.933766Z","shell.execute_reply.started":"2025-12-06T05:21:39.343413Z","shell.execute_reply":"2025-12-06T05:21:57.933062Z"}},"outputs":[{"name":"stdout","text":"Installing PyG (this may take a moment)...\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.2/545.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.1/781.1 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalled PyG; continuing.\nLoading arrays from DATA_DIR: /kaggle/input/gnn-fakenews-graph-data\nLoaded arrays shapes: (5425,) (500,) (5425, 768) (5425, 10) (5425, 310)\nNo saved graph_list found — rebuilding up to MAX_GRAPHS = 500\nTotal available graphs: 500\nBuilt graphs: 500 Skipped: 0\nSaved built graph_list to /kaggle/working/graph_dataset/graph_list_500.pt\nPrepared DataLoaders -> train: 400 val: 100\nExample batch shapes (first batch):\n batch.x.shape: torch.Size([360, 778])\n batch.edge_index.shape: torch.Size([2, 624])\n batch.y.shape: torch.Size([32])\nSetup complete. Ready to run experiments (CELL 4.3).\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# === RESTORE TRAINING UTILITIES (CELL 4.2 RE-RUN) ===\nimport torch\nimport torch.nn.functional as F\nfrom sklearn.metrics import accuracy_score, f1_score\n\ndef train_one_epoch(model, loader, optimizer, loss_fn, device):\n    model.train()\n    total_loss = 0.0\n    total = 0\n    correct = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index, batch.batch)\n        loss = loss_fn(out, batch.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=1)\n        correct += (preds == batch.y).sum().item()\n        total += batch.num_graphs\n    return total_loss / total, correct / total\n\ndef evaluate_model(model, loader, device):\n    model.eval()\n    ys, preds = [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            out = model(batch.x, batch.edge_index, batch.batch)\n            p = out.argmax(dim=1).cpu().numpy()\n            preds.extend(p.tolist())\n            ys.extend(batch.y.cpu().numpy().tolist())\n    return {\n        \"accuracy\": accuracy_score(ys, preds),\n        \"f1_macro\": f1_score(ys, preds, average='macro')\n    }\n\ndef run_training(model_name, train_loader, val_loader, in_channels, device,\n                 epochs=2, lr=1e-3, hidden=128,\n                 checkpoint_dir=\"/kaggle/working/checkpoints\"):\n    import os\n    from torch_geometric.nn import global_mean_pool\n\n    model = get_model(model_name, in_channels, hidden).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    loss_fn = torch.nn.CrossEntropyLoss()\n\n    os.makedirs(checkpoint_dir, exist_ok=True)\n\n    best_val_f1 = -1\n    best_path = None\n    history = {\"epoch\":[], \"train_loss\":[], \"train_acc\":[], \"val_acc\":[], \"val_f1\":[]}\n\n    for epoch in range(1, epochs+1):\n        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n        val = evaluate_model(model, val_loader, device)\n        val_acc, val_f1 = val[\"accuracy\"], val[\"f1_macro\"]\n\n        print(f\"[{model_name}] Epoch {epoch}: train_loss={train_loss:.4f} train_acc={train_acc:.4f} val_acc={val_acc:.4f} val_f1={val_f1:.4f}\")\n\n        history[\"epoch\"].append(epoch)\n        history[\"train_loss\"].append(train_loss)\n        history[\"train_acc\"].append(train_acc)\n        history[\"val_acc\"].append(val_acc)\n        history[\"val_f1\"].append(val_f1)\n\n        # checkpoint\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            best_path = os.path.join(checkpoint_dir, f\"best_{model_name}.pt\")\n            torch.save(model.state_dict(), best_path)\n            print(\"Saved best checkpoint →\", best_path)\n\n    return history, best_path\n\nprint(\"Training utilities restored (train_one_epoch, evaluate_model, run_training).\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T05:25:38.767427Z","iopub.execute_input":"2025-12-06T05:25:38.768335Z","iopub.status.idle":"2025-12-06T05:25:39.163577Z","shell.execute_reply.started":"2025-12-06T05:25:38.768297Z","shell.execute_reply":"2025-12-06T05:25:39.162817Z"}},"outputs":[{"name":"stdout","text":"Training utilities restored (train_one_epoch, evaluate_model, run_training).\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# === MASTER CELL: define models + ensure trainer exists + run short experiments ===\nimport os, torch, random, numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# ---- 1) Model definitions (GCN, GAT, SAGE) ----\nfrom torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_mean_pool\n\nclass GCNGraphClassifier(nn.Module):\n    def __init__(self, in_channels, hidden=128, num_classes=2):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, hidden)\n        self.conv2 = GCNConv(hidden, hidden)\n        self.lin = nn.Linear(hidden, num_classes)\n    def forward(self, x, edge_index, batch):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\nclass GATGraphClassifier(nn.Module):\n    def __init__(self, in_channels, hidden=128, num_classes=2, heads=4):\n        super().__init__()\n        self.gat1 = GATConv(in_channels, hidden // heads, heads=heads)\n        self.gat2 = GATConv(hidden, hidden // heads, heads=heads)\n        self.lin = nn.Linear(hidden, num_classes)\n    def forward(self, x, edge_index, batch):\n        x = F.elu(self.gat1(x, edge_index))\n        x = F.elu(self.gat2(x, edge_index))\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\nclass SAGEGraphClassifier(nn.Module):\n    def __init__(self, in_channels, hidden=128, num_classes=2):\n        super().__init__()\n        self.sage1 = SAGEConv(in_channels, hidden)\n        self.sage2 = SAGEConv(hidden, hidden)\n        self.lin = nn.Linear(hidden, num_classes)\n    def forward(self, x, edge_index, batch):\n        x = F.relu(self.sage1(x, edge_index))\n        x = F.relu(self.sage2(x, edge_index))\n        x = global_mean_pool(x, batch)\n        return self.lin(x)\n\ndef get_model(name, in_channels, hidden=128):\n    name = name.lower()\n    if name == \"gcn\":\n        return GCNGraphClassifier(in_channels, hidden)\n    if name == \"gat\":\n        return GATGraphClassifier(in_channels, hidden)\n    if name == \"sage\":\n        return SAGEGraphClassifier(in_channels, hidden)\n    raise ValueError(\"Unknown model: \"+name)\n\nprint(\"Model factory defined: get_model('gcn'|'gat'|'sage', in_channels, hidden)\")\n\n# ---- 2) Re-define training utilities if missing ----\ntry:\n    run_training  # if already defined, keep it\n    print(\"run_training already defined — reusing it.\")\nexcept NameError:\n    print(\"Defining run_training utilities (train_one_epoch, evaluate_model, run_training)...\")\n    from sklearn.metrics import accuracy_score, f1_score\n    def train_one_epoch(model, loader, optimizer, loss_fn, device):\n        model.train()\n        total_loss = 0.0; total = 0; correct = 0\n        for batch in loader:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = loss_fn(out, batch.y)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * batch.num_graphs\n            preds = out.argmax(dim=1)\n            correct += (preds == batch.y).sum().item()\n            total += batch.num_graphs\n        return total_loss / total, correct / total\n\n    def evaluate_model(model, loader, device):\n        model.eval()\n        ys, preds = [], []\n        with torch.no_grad():\n            for batch in loader:\n                batch = batch.to(device)\n                out = model(batch.x, batch.edge_index, batch.batch)\n                p = out.argmax(dim=1).cpu().numpy()\n                preds.extend(p.tolist())\n                ys.extend(batch.y.cpu().numpy().tolist())\n        return {\"accuracy\": accuracy_score(ys, preds), \"f1_macro\": f1_score(ys, preds, average='macro')}\n\n    def run_training(model_name, train_loader, val_loader, in_channels, device,\n                     epochs=2, lr=1e-3, hidden=128, checkpoint_dir=\"/kaggle/working/checkpoints\"):\n        model = get_model(model_name, in_channels, hidden).to(device)\n        opt = torch.optim.Adam(model.parameters(), lr=lr)\n        loss_fn = torch.nn.CrossEntropyLoss()\n        os.makedirs(checkpoint_dir, exist_ok=True)\n        best_val_f1 = -1.0\n        best_path = None\n        history = {\"epoch\":[],\"train_loss\":[],\"train_acc\":[],\"val_acc\":[],\"val_f1\":[]}\n        for epoch in range(1, epochs+1):\n            train_loss, train_acc = train_one_epoch(model, train_loader, opt, loss_fn, device)\n            val = evaluate_model(model, val_loader, device)\n            val_acc, val_f1 = val[\"accuracy\"], val[\"f1_macro\"]\n            print(f\"[{model_name}] Epoch {epoch}: train_loss={train_loss:.4f} train_acc={train_acc:.4f} val_acc={val_acc:.4f} val_f1={val_f1:.4f}\")\n            history[\"epoch\"].append(epoch)\n            history[\"train_loss\"].append(train_loss)\n            history[\"train_acc\"].append(train_acc)\n            history[\"val_acc\"].append(val_acc)\n            history[\"val_f1\"].append(val_f1)\n            if val_f1 > best_val_f1:\n                best_val_f1 = val_f1\n                best_path = os.path.join(checkpoint_dir, f\"best_{model_name}.pt\")\n                torch.save(model.state_dict(), best_path)\n                print(\"Saved best checkpoint →\", best_path)\n        return history, best_path\n\nprint(\"Training utilities ready.\")\n\n# ---- 3) Run the short experiments now ----\n# Verify required globals exist\nif 'train_loader' not in globals() or 'val_loader' not in globals() or 'graph_list' not in globals():\n    raise RuntimeError(\"train_loader / val_loader / graph_list not found in memory. Re-run the setup cell that creates them before executing this master cell.\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nin_channels = graph_list[0].num_node_features\nmodels_to_test = [\"gcn\",\"gat\",\"sage\"]\nresults = {}\nfor mname in models_to_test:\n    print(\"\\n=== Running model:\", mname, \"===\")\n    hist, best_path = run_training(mname, train_loader, val_loader, in_channels, device,\n                                  epochs=2, lr=1e-3, hidden=128,\n                                  checkpoint_dir=\"/kaggle/working/checkpoints\")\n    results[mname] = {\"history\": hist, \"best_path\": best_path}\n\n# ---- 4) short summary table saved ----\nimport pandas as pd\nrows = []\nfor mname, info in results.items():\n    h = info[\"history\"]\n    rows.append({\"model\":mname,\n                 \"best_val_f1\": max(h[\"val_f1\"]) if len(h[\"val_f1\"])>0 else None,\n                 \"best_val_acc\": max(h[\"val_acc\"]) if len(h[\"val_acc\"])>0 else None,\n                 \"best_path\": info[\"best_path\"]})\ndf = pd.DataFrame(rows).sort_values(\"best_val_f1\", ascending=False)\nprint(\"\\nExperiment summary:\")\nprint(df)\ndf.to_csv(\"/kaggle/working/short_experiments_summary.csv\", index=False)\nprint(\"Saved /kaggle/working/short_experiments_summary.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T05:40:37.593122Z","iopub.execute_input":"2025-12-06T05:40:37.593540Z","iopub.status.idle":"2025-12-06T05:40:39.268015Z","shell.execute_reply.started":"2025-12-06T05:40:37.593512Z","shell.execute_reply":"2025-12-06T05:40:39.267284Z"}},"outputs":[{"name":"stdout","text":"Model factory defined: get_model('gcn'|'gat'|'sage', in_channels, hidden)\nrun_training already defined — reusing it.\nTraining utilities ready.\n\n=== Running model: gcn ===\n[gcn] Epoch 1: train_loss=0.5379 train_acc=0.7550 val_acc=0.9400 val_f1=0.9380\nSaved best checkpoint → /kaggle/working/checkpoints/best_gcn.pt\n[gcn] Epoch 2: train_loss=0.2509 train_acc=0.9275 val_acc=0.9500 val_f1=0.9491\nSaved best checkpoint → /kaggle/working/checkpoints/best_gcn.pt\n\n=== Running model: gat ===\n[gat] Epoch 1: train_loss=0.5900 train_acc=0.7000 val_acc=0.9500 val_f1=0.9488\nSaved best checkpoint → /kaggle/working/checkpoints/best_gat.pt\n[gat] Epoch 2: train_loss=0.2605 train_acc=0.9150 val_acc=0.9400 val_f1=0.9394\n\n=== Running model: sage ===\n[sage] Epoch 1: train_loss=0.4578 train_acc=0.8225 val_acc=0.8900 val_f1=0.8839\nSaved best checkpoint → /kaggle/working/checkpoints/best_sage.pt\n[sage] Epoch 2: train_loss=0.2124 train_acc=0.9200 val_acc=0.9400 val_f1=0.9380\nSaved best checkpoint → /kaggle/working/checkpoints/best_sage.pt\n\nExperiment summary:\n  model  best_val_f1  best_val_acc                                 best_path\n0   gcn     0.949140          0.95   /kaggle/working/checkpoints/best_gcn.pt\n1   gat     0.948849          0.95   /kaggle/working/checkpoints/best_gat.pt\n2  sage     0.937991          0.94  /kaggle/working/checkpoints/best_sage.pt\nSaved /kaggle/working/short_experiments_summary.csv\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}