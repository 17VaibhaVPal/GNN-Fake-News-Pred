{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13984787,"sourceType":"datasetVersion","datasetId":8914055}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 1\nimport os, numpy as np, pandas as pd\n\nDATA_DIR = \"/kaggle/input/gnn-fakenews-graph-data\"\nprint(\"DATA_DIR:\", DATA_DIR)\nprint(\"Files:\", sorted(os.listdir(DATA_DIR)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:38:17.706937Z","iopub.execute_input":"2025-12-04T06:38:17.707500Z","iopub.status.idle":"2025-12-04T06:38:17.718319Z","shell.execute_reply.started":"2025-12-04T06:38:17.707472Z","shell.execute_reply":"2025-12-04T06:38:17.717756Z"}},"outputs":[{"name":"stdout","text":"DATA_DIR: /kaggle/input/gnn-fakenews-graph-data\nFiles: ['A.txt', 'graph_labels.npy', 'new_bert_feature.npz', 'new_content_feature.npz', 'new_profile_feature.npz', 'node_graph_id.npy']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 2 — Load arrays & inspect shapes\n\nimport numpy as np\nimport os\n\nA_path = os.path.join(DATA_DIR, \"A.txt\")\nnode_graph_id = np.load(os.path.join(DATA_DIR, \"node_graph_id.npy\"))\ngraph_labels = np.load(os.path.join(DATA_DIR, \"graph_labels.npy\"))\nbert = np.load(os.path.join(DATA_DIR, \"new_bert_feature.npz\"))[\"data\"]\nprofile = np.load(os.path.join(DATA_DIR, \"new_profile_feature.npz\"))[\"data\"]\ncontent = np.load(os.path.join(DATA_DIR, \"new_content_feature.npz\"))[\"data\"]\n\nprint(\"node_graph_id shape:\", node_graph_id.shape)\nprint(\"graph_labels shape:\", graph_labels.shape)\nprint(\"bert shape:\", bert.shape)\nprint(\"profile shape:\", profile.shape)\nprint(\"content shape:\", content.shape)\n\n# show first 5 edges only\nprint(\"\\nSample edges from A.txt:\")\nwith open(A_path) as f:\n    for _ in range(5):\n        print(f.readline().strip())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:44:28.372056Z","iopub.execute_input":"2025-12-04T06:44:28.372896Z","iopub.status.idle":"2025-12-04T06:44:28.998975Z","shell.execute_reply.started":"2025-12-04T06:44:28.372868Z","shell.execute_reply":"2025-12-04T06:44:28.998141Z"}},"outputs":[{"name":"stdout","text":"node_graph_id shape: (5425,)\ngraph_labels shape: (500,)\nbert shape: (5425, 768)\nprofile shape: (5425, 10)\ncontent shape: (5425, 310)\n\nSample edges from A.txt:\n0 1\n0 2\n0 3\n0 4\n0 5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Install PyTorch Geometric on Kaggle\n# This installs the correct wheels that match the PyTorch version on Kaggle\n\n!pip install -q torch_geometric\n!pip install -q torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:46:38.317387Z","iopub.execute_input":"2025-12-04T06:46:38.317724Z","iopub.status.idle":"2025-12-04T06:46:50.402544Z","shell.execute_reply.started":"2025-12-04T06:46:38.317690Z","shell.execute_reply":"2025-12-04T06:46:50.401842Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.0/494.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.9/750.9 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch_geometric\nimport torch\nfrom torch_geometric.data import Data\n\nprint(\"PyG version:\", torch_geometric.__version__)\nprint(\"Torch version:\", torch.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:49:17.702146Z","iopub.execute_input":"2025-12-04T06:49:17.703011Z","iopub.status.idle":"2025-12-04T06:49:26.885368Z","shell.execute_reply.started":"2025-12-04T06:49:17.702977Z","shell.execute_reply":"2025-12-04T06:49:26.884587Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  import torch_geometric.typing\n/usr/local/lib/python3.11/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  import torch_geometric.typing\n/usr/local/lib/python3.11/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  import torch_geometric.typing\n/usr/local/lib/python3.11/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n  import torch_geometric.typing\n","output_type":"stream"},{"name":"stdout","text":"PyG version: 2.7.0\nTorch version: 2.6.0+cu124\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Cell 3 — Build PyTorch Geometric Data object (single big graph)\n\nimport torch\nfrom torch_geometric.data import Data\nimport numpy as np\nimport os\n\nprint(\"Building graph...\")\n\n# ---- 1. Load edges ----\nedges = []\nwith open(os.path.join(DATA_DIR, \"A.txt\"), \"r\") as f:\n    for line in f:\n        u, v = map(int, line.strip().split())\n        edges.append([u, v])\n\nedges = np.array(edges, dtype=np.int64)\nedge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n\nprint(\"Edge index shape:\", edge_index.shape)\n\n# ---- 2. Combine node features: BERT + profile ----\n# bert shape: (N_nodes, 768)\n# profile shape: (N_nodes, 10)\nnode_features = np.hstack([bert, profile])   # final dim = 778\nx = torch.from_numpy(node_features).float()\n\nprint(\"Node features shape (x):\", x.shape)\n\n# ---- 3. Build big Data object ----\ndata = Data(x=x, edge_index=edge_index)\n\nprint(\"\\n=== PyG Data Object Created ===\")\nprint(data)\nprint(\"Number of nodes:\", data.num_nodes)\nprint(\"Number of edges:\", data.num_edges)\nprint(\"Node feature dimension:\", data.num_node_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:53:01.987154Z","iopub.execute_input":"2025-12-04T06:53:01.988155Z","iopub.status.idle":"2025-12-04T06:53:02.036033Z","shell.execute_reply.started":"2025-12-04T06:53:01.988125Z","shell.execute_reply":"2025-12-04T06:53:02.035326Z"}},"outputs":[{"name":"stdout","text":"Building graph...\nEdge index shape: torch.Size([2, 9350])\nNode features shape (x): torch.Size([5425, 778])\n\n=== PyG Data Object Created ===\nData(x=[5425, 778], edge_index=[2, 9350])\nNumber of nodes: 5425\nNumber of edges: 9350\nNode feature dimension: 778\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Cell 4 - Define test GCN\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nclass SimpleGCN(nn.Module):\n    def __init__(self, in_channels, hidden=128, out_channels=2):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, hidden)\n        self.conv2 = GCNConv(hidden, hidden)\n        self.lin = nn.Linear(hidden, out_channels)\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = x.mean(dim=0, keepdim=True)\n        return self.lin(x)\n\nmodel = SimpleGCN(data.num_node_features)\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:53:44.012617Z","iopub.execute_input":"2025-12-04T06:53:44.013502Z","iopub.status.idle":"2025-12-04T06:53:44.069876Z","shell.execute_reply.started":"2025-12-04T06:53:44.013465Z","shell.execute_reply":"2025-12-04T06:53:44.069116Z"}},"outputs":[{"name":"stdout","text":"SimpleGCN(\n  (conv1): GCNConv(778, 128)\n  (conv2): GCNConv(128, 128)\n  (lin): Linear(in_features=128, out_features=2, bias=True)\n)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Cell 5 - Forward test\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ndata = data.to(device)\n\nmodel.eval()\nwith torch.no_grad():\n    out = model(data.x, data.edge_index)\n\nprint(\"Output logits:\", out)\nprint(\"Shape:\", out.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:53:54.557756Z","iopub.execute_input":"2025-12-04T06:53:54.558550Z","iopub.status.idle":"2025-12-04T06:53:55.960350Z","shell.execute_reply.started":"2025-12-04T06:53:54.558515Z","shell.execute_reply":"2025-12-04T06:53:55.959629Z"}},"outputs":[{"name":"stdout","text":"Output logits: tensor([[0.1338, 0.4230]], device='cuda:0')\nShape: torch.Size([1, 2])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# CELL A — per-graph builder parameters\nimport os, random, numpy as np, torch\nfrom collections import defaultdict\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\n# Safety limits (tune as needed)\nMAX_GRAPHS = 2000        # max number of article graphs to build (set small for testing)\nMIN_NODES_PER_GRAPH = 2  # skip extremely tiny graphs\nDATA_DIR = \"/kaggle/input/gnn-fakenews-graph-data\"\n\nprint(\"MAX_GRAPHS:\", MAX_GRAPHS)\nprint(\"DATA_DIR:\", DATA_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:06:33.781625Z","iopub.execute_input":"2025-12-04T19:06:33.781896Z","iopub.status.idle":"2025-12-04T19:06:37.651785Z","shell.execute_reply.started":"2025-12-04T19:06:33.781870Z","shell.execute_reply":"2025-12-04T19:06:37.650987Z"}},"outputs":[{"name":"stdout","text":"MAX_GRAPHS: 2000\nDATA_DIR: /kaggle/input/gnn-fakenews-graph-data\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install PyTorch Geometric on Kaggle (CPU version)\n!pip install -q torch_geometric\n\n# Install matching CPU wheels for PyTorch 2.6.0+cu124\n!pip install -q \\\n    torch_scatter \\\n    torch_sparse \\\n    torch_cluster \\\n    torch_spline_conv \\\n    -f https://data.pyg.org/whl/torch-2.6.0+cpu.html\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:08:15.359658Z","iopub.execute_input":"2025-12-04T19:08:15.360423Z","iopub.status.idle":"2025-12-04T19:08:25.298486Z","shell.execute_reply.started":"2025-12-04T19:08:15.360394Z","shell.execute_reply":"2025-12-04T19:08:25.297583Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.2/545.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.1/781.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch_geometric\nfrom torch_geometric.data import Data\n\nprint(\"PyG version:\", torch_geometric.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:08:41.781883Z","iopub.execute_input":"2025-12-04T19:08:41.782185Z","iopub.status.idle":"2025-12-04T19:08:49.052380Z","shell.execute_reply.started":"2025-12-04T19:08:41.782156Z","shell.execute_reply":"2025-12-04T19:08:49.051595Z"}},"outputs":[{"name":"stdout","text":"PyG version: 2.7.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- RELOAD DATASET (Cell 2 again) ---\n\nimport numpy as np\nimport os\n\nDATA_DIR = \"/kaggle/input/gnn-fakenews-graph-data\"\n\nA_path = os.path.join(DATA_DIR, \"A.txt\")\nnode_graph_id = np.load(os.path.join(DATA_DIR, \"node_graph_id.npy\"))\ngraph_labels = np.load(os.path.join(DATA_DIR, \"graph_labels.npy\"))\nbert = np.load(os.path.join(DATA_DIR, \"new_bert_feature.npz\"))[\"data\"]\nprofile = np.load(os.path.join(DATA_DIR, \"new_profile_feature.npz\"))[\"data\"]\ncontent = np.load(os.path.join(DATA_DIR, \"new_content_feature.npz\"))[\"data\"]\n\nprint(\"Loaded Shapes:\")\nprint(\"node_graph_id:\", node_graph_id.shape)\nprint(\"graph_labels:\", graph_labels.shape)\nprint(\"bert:\", bert.shape)\nprint(\"profile:\", profile.shape)\nprint(\"content:\", content.shape)\n\n# show edges preview\nwith open(A_path) as f:\n    for _ in range(5):\n        print(\"Edge:\", f.readline().strip())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:10:27.175788Z","iopub.execute_input":"2025-12-04T19:10:27.176137Z","iopub.status.idle":"2025-12-04T19:10:27.624621Z","shell.execute_reply.started":"2025-12-04T19:10:27.176116Z","shell.execute_reply":"2025-12-04T19:10:27.623878Z"}},"outputs":[{"name":"stdout","text":"Loaded Shapes:\nnode_graph_id: (5425,)\ngraph_labels: (500,)\nbert: (5425, 768)\nprofile: (5425, 10)\ncontent: (5425, 310)\nEdge: 0 1\nEdge: 0 2\nEdge: 0 3\nEdge: 0 4\nEdge: 0 5\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# CELL B — Build per-article Data objects (memory-aware streaming)\nfrom torch_geometric.data import Data\nimport torch\n\n# load edge list again (safe)\nA_path = os.path.join(DATA_DIR, \"A.txt\")\nedges_full = []\nwith open(A_path) as f:\n    for line in f:\n        u,v = map(int, line.strip().split())\n        edges_full.append((u,v))\n# Convert to lists for fast mask checks\nedges_full = np.array(edges_full, dtype=np.int64)\n\n# Build map: graph_id -> list of node indices\ngraph_to_nodes = defaultdict(list)\nfor nid, gid in enumerate(node_graph_id):\n    graph_to_nodes[int(gid)].append(nid)\n\nprint(\"Total graphs available:\", len(graph_to_nodes))\n\n# Build Data objects up to MAX_GRAPHS\ngraph_list = []\nskipped = 0\nfor gid, nodes in list(graph_to_nodes.items())[:MAX_GRAPHS]:\n    # select edges where both endpoints in nodes\n    node_set = set(nodes)\n    # mask edges: find edges where both endpoints in node_set\n    # faster: use boolean mask over numpy arrays\n    # create a set for faster containment checks for smaller graphs\n    e_mask_indices = []\n    # iterate edges_full once but break early? We'll vectorize using numpy:\n    # filter edges where both endpoints in node_set\n    # because node_set size is small (per-graph), do Python loop for simplicity\n    e_list = []\n    for (u,v) in edges_full:\n        if u in node_set and v in node_set:\n            e_list.append([u - nodes[0], v - nodes[0]])  # will remap indices below\n    if len(e_list) == 0 or len(nodes) < MIN_NODES_PER_GRAPH:\n        skipped += 1\n        continue\n\n    # Remap global node ids in 'nodes' to local ids 0..(len(nodes)-1)\n    global_to_local = {g:i for i,g in enumerate(nodes)}\n    e_idx = []\n    for (u,v) in e_list:\n        # but the above had wrong remap; let's recompute reliably:\n        pass\n# We'll implement a clearer loop below — restart building properly\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:10:50.935449Z","iopub.execute_input":"2025-12-04T19:10:50.936026Z","iopub.status.idle":"2025-12-04T19:10:55.402824Z","shell.execute_reply.started":"2025-12-04T19:10:50.935999Z","shell.execute_reply":"2025-12-04T19:10:55.402250Z"}},"outputs":[{"name":"stdout","text":"Total graphs available: 500\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# CELL B (working reliable version) — Build per-graph Data objects\nfrom torch_geometric.data import Data\nimport torch\n\n# convert edges_full to list of tuples for iteration\nedges_list = [tuple(e) for e in edges_full.tolist()]\n\ngraph_list = []\nskipped = 0\nbuilt = 0\n\nfor gid, nodes in list(graph_to_nodes.items()):\n    if built >= MAX_GRAPHS:\n        break\n    nodes_sorted = sorted(nodes)  # sorted global node ids\n    node_set = set(nodes_sorted)\n    # build mapping global -> local\n    g2l = {g:i for i,g in enumerate(nodes_sorted)}\n    # collect edges that lie within node_set\n    e_local = []\n    for (u,v) in edges_list:\n        if u in node_set and v in node_set:\n            e_local.append([g2l[u], g2l[v]])\n    if len(e_local) == 0 or len(nodes_sorted) < MIN_NODES_PER_GRAPH:\n        skipped += 1\n        continue\n\n    edge_index = torch.tensor(e_local, dtype=torch.long).t().contiguous()\n    # node features for this subgraph\n    x_sub = torch.from_numpy(np.hstack([bert[nodes_sorted], profile[nodes_sorted]])).float()\n    y = torch.tensor([int(graph_labels[gid])], dtype=torch.long)\n    data_obj = Data(x=x_sub, edge_index=edge_index, y=y)\n    graph_list.append(data_obj)\n    built += 1\n\nprint(\"Built graphs:\", built, \"Skipped:\", skipped)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:11:20.877652Z","iopub.execute_input":"2025-12-04T19:11:20.877991Z","iopub.status.idle":"2025-12-04T19:11:21.387250Z","shell.execute_reply.started":"2025-12-04T19:11:20.877969Z","shell.execute_reply":"2025-12-04T19:11:21.386451Z"}},"outputs":[{"name":"stdout","text":"Built graphs: 500 Skipped: 0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Inspect first 3 graphs in graph_list\nfor i in range(3):\n    g = graph_list[i]\n    print(f\"Graph {i}: nodes={g.num_nodes}, edges={g.num_edges}, x.shape={g.x.shape}, y={g.y}\")\n    print(\"edge_index sample:\", g.edge_index[:, :min(8, g.edge_index.shape[1])].t().tolist())\n    print(\"---\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:33:18.242395Z","iopub.execute_input":"2025-12-04T19:33:18.243122Z","iopub.status.idle":"2025-12-04T19:33:18.262047Z","shell.execute_reply.started":"2025-12-04T19:33:18.243095Z","shell.execute_reply":"2025-12-04T19:33:18.261312Z"}},"outputs":[{"name":"stdout","text":"Graph 0: nodes=13, edges=23, x.shape=torch.Size([13, 778]), y=tensor([1])\nedge_index sample: [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8]]\n---\nGraph 1: nodes=13, edges=23, x.shape=torch.Size([13, 778]), y=tensor([1])\nedge_index sample: [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8]]\n---\nGraph 2: nodes=15, edges=27, x.shape=torch.Size([15, 778]), y=tensor([0])\nedge_index sample: [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8]]\n---\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Save graph_list to /kaggle/working so it persists in the Notebook Output\nimport torch, os\nout_dir = \"/kaggle/working/graph_dataset\"\nos.makedirs(out_dir, exist_ok=True)\ntorch.save(graph_list, os.path.join(out_dir, \"graph_list_500.pt\"))\nprint(\"Saved graph_list length:\", len(graph_list))\nprint(\"Files:\", os.listdir(out_dir))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:34:11.144017Z","iopub.execute_input":"2025-12-04T19:34:11.144703Z","iopub.status.idle":"2025-12-04T19:34:11.222893Z","shell.execute_reply.started":"2025-12-04T19:34:11.144678Z","shell.execute_reply":"2025-12-04T19:34:11.222315Z"}},"outputs":[{"name":"stdout","text":"Saved graph_list length: 500\nFiles: ['graph_list_500.pt']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# CELL C — inspect first graph\nprint(\"Example graph (0): nodes:\", graph_list[0].num_nodes, \"edges:\", graph_list[0].num_edges)\nprint(\"x.shape:\", graph_list[0].x.shape, \"y:\", graph_list[0].y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:34:41.098631Z","iopub.execute_input":"2025-12-04T19:34:41.099010Z","iopub.status.idle":"2025-12-04T19:34:41.104137Z","shell.execute_reply.started":"2025-12-04T19:34:41.098988Z","shell.execute_reply":"2025-12-04T19:34:41.103426Z"}},"outputs":[{"name":"stdout","text":"Example graph (0): nodes: 13 edges: 23\nx.shape: torch.Size([13, 778]) y: tensor([1])\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# CELL D — make DataLoaders\nfrom torch_geometric.loader import DataLoader\nrandom.shuffle(graph_list)\nsplit = int(0.8 * len(graph_list))\ntrain_list = graph_list[:split]\nval_list = graph_list[split:]\n\ntrain_loader = DataLoader(train_list, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_list, batch_size=32)\n\nprint(\"Train graphs:\", len(train_list), \"Val graphs:\", len(val_list))\n# show one batch shapes\nfor batch in train_loader:\n    print(\"Batch.x.shape:\", batch.x.shape, \"batch.edge_index.shape:\", batch.edge_index.shape, \"batch.y.shape:\", batch.y.shape)\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:34:56.242371Z","iopub.execute_input":"2025-12-04T19:34:56.242645Z","iopub.status.idle":"2025-12-04T19:34:56.280113Z","shell.execute_reply.started":"2025-12-04T19:34:56.242622Z","shell.execute_reply":"2025-12-04T19:34:56.279468Z"}},"outputs":[{"name":"stdout","text":"Train graphs: 400 Val graphs: 100\nBatch.x.shape: torch.Size([344, 778]) batch.edge_index.shape: torch.Size([2, 592]) batch.y.shape: torch.Size([32])\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# CELL E — GCN model (graph classification)\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\nclass GCNGraphClassifier(nn.Module):\n    def __init__(self, in_channels, hidden=128, num_classes=2):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, hidden)\n        self.conv2 = GCNConv(hidden, hidden)\n        self.lin = nn.Linear(hidden, num_classes)\n    def forward(self, x, edge_index, batch):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = global_mean_pool(x, batch)   # graph-level pooling\n        return self.lin(x)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = GCNGraphClassifier(in_channels=graph_list[0].num_node_features, hidden=128, num_classes=2).to(device)\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:37:06.103146Z","iopub.execute_input":"2025-12-04T19:37:06.103463Z","iopub.status.idle":"2025-12-04T19:37:06.356023Z","shell.execute_reply.started":"2025-12-04T19:37:06.103441Z","shell.execute_reply":"2025-12-04T19:37:06.355204Z"}},"outputs":[{"name":"stdout","text":"GCNGraphClassifier(\n  (conv1): GCNConv(778, 128)\n  (conv2): GCNConv(128, 128)\n  (lin): Linear(in_features=128, out_features=2, bias=True)\n)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# CELL F — training loop (quick demo)\nimport torch\nfrom torch.nn import CrossEntropyLoss\nfrom tqdm import tqdm\n\nopt = torch.optim.Adam(model.parameters(), lr=1e-3)\nloss_fn = CrossEntropyLoss()\n\nEPOCHS = 5\n\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    total_loss = 0.0\n    total = 0\n    correct = 0\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch} train\"):\n        batch = batch.to(device)\n        opt.zero_grad()\n        out = model(batch.x, batch.edge_index, batch.batch)\n        loss = loss_fn(out, batch.y)\n        loss.backward()\n        opt.step()\n        total_loss += loss.item() * batch.num_graphs\n        preds = out.argmax(dim=1)\n        correct += (preds == batch.y).sum().item()\n        total += batch.num_graphs\n    avg_loss = total_loss / total\n    acc = correct / total\n    print(f\"[Epoch {epoch}] train_loss: {avg_loss:.4f} train_acc: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:37:38.680107Z","iopub.execute_input":"2025-12-04T19:37:38.680855Z","iopub.status.idle":"2025-12-04T19:37:39.940365Z","shell.execute_reply.started":"2025-12-04T19:37:38.680810Z","shell.execute_reply":"2025-12-04T19:37:39.939590Z"}},"outputs":[{"name":"stderr","text":"Epoch 1 train: 100%|██████████| 13/13 [00:00<00:00, 13.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] train_loss: 0.5014 train_acc: 0.8025\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 train: 100%|██████████| 13/13 [00:00<00:00, 171.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] train_loss: 0.2403 train_acc: 0.9050\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 train: 100%|██████████| 13/13 [00:00<00:00, 181.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] train_loss: 0.2492 train_acc: 0.8850\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 train: 100%|██████████| 13/13 [00:00<00:00, 179.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] train_loss: 0.1650 train_acc: 0.9350\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 train: 100%|██████████| 13/13 [00:00<00:00, 182.38it/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] train_loss: 0.1230 train_acc: 0.9600\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# CELL G — evaluate on val set\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\nmodel.eval()\nys, preds = [], []\nwith torch.no_grad():\n    for batch in val_loader:\n        batch = batch.to(device)\n        out = model(batch.x, batch.edge_index, batch.batch)\n        p = out.argmax(dim=1).cpu().numpy()\n        preds.extend(p.tolist())\n        ys.extend(batch.y.cpu().numpy().tolist())\n\nprint(\"Val accuracy:\", accuracy_score(ys, preds))\nprint(\"Val f1 (macro):\", f1_score(ys, preds, average='macro'))\nprint(\"Val precision:\", precision_score(ys, preds, average='macro', zero_division=0))\nprint(\"Val recall:\", recall_score(ys, preds, average='macro', zero_division=0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:38:19.356815Z","iopub.execute_input":"2025-12-04T19:38:19.357160Z","iopub.status.idle":"2025-12-04T19:38:19.791083Z","shell.execute_reply.started":"2025-12-04T19:38:19.357138Z","shell.execute_reply":"2025-12-04T19:38:19.790350Z"}},"outputs":[{"name":"stdout","text":"Val accuracy: 0.91\nVal f1 (macro): 0.9099189270343309\nVal precision: 0.9134460547504026\nVal recall: 0.9109643857543017\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# CELL H — save model and metadata\nout_path = \"/kaggle/working/gnn_model\"\nos.makedirs(out_path, exist_ok=True)\ntorch.save(model.state_dict(), os.path.join(out_path, \"gcn_graph_classifier.pt\"))\n# save a small metadata file\nwith open(os.path.join(out_path, \"metadata.txt\"), \"w\") as f:\n    f.write(f\"Built graphs: {len(graph_list)}\\n\")\n    f.write(f\"Train graphs: {len(train_list)}\\nVal graphs: {len(val_list)}\\n\")\nprint(\"Saved model to\", out_path)\nprint(os.listdir(out_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:38:39.990491Z","iopub.execute_input":"2025-12-04T19:38:39.991321Z","iopub.status.idle":"2025-12-04T19:38:39.998986Z","shell.execute_reply.started":"2025-12-04T19:38:39.991295Z","shell.execute_reply":"2025-12-04T19:38:39.998375Z"}},"outputs":[{"name":"stdout","text":"Saved model to /kaggle/working/gnn_model\n['gcn_graph_classifier.pt', 'metadata.txt']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}